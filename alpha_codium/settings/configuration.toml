[config]
#model="gpt-4"
model = "gpt-3.5-turbo"
requests_per_minute=60
fallback_models =[]
#fallback_models=["gpt-3.5-turbo-16k"]
git_provider="github"
publish_output=true
publish_output_progress=true
verbosity_level=0 # 0,1,2
use_extra_bad_extensions=false
use_repo_settings_file=true
ai_timeout=180
max_description_tokens = 500
max_commits_tokens = 500
secret_provider="google_cloud_storage"
cli_mode=false

[solve]
use_baselines=true
do_recording = false
use_recording = false
terminate_on_failure = false
max_allowed_counter = 1 # number of iterations to pass public tests

[etl]
private_dataset_cache_dir="~/.cache/huggingface/datasets/alpha_codium"
#private_dataset_cache_dir='/Users/talrid/Desktop/code_contest_dataset'

[code_tester]
tester_type="local" # local, code_contests
sandbox=true
calc_trace=true
use_trace=false
max_trace_length=100
trace_depth=4


[code_contests_tester]
num_threads = 4
stop_on_first_failure = false
timeout = 10
path_to_python_bin = "/usr/bin/python3.9"
path_to_python_lib = ["/usr/lib", "/usr/lib/python3.9"]



