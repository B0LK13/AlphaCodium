[config]
model="gpt-4"
fallback_models=["gpt-3.5-turbo-16k"]
git_provider="github"
publish_output=true
publish_output_progress=true
verbosity_level=0 # 0,1,2
use_extra_bad_extensions=false
use_repo_settings_file=true
ai_timeout=180
max_description_tokens = 500
max_commits_tokens = 500
secret_provider="google_cloud_storage"
cli_mode=false


[etl]
private_dataset_cache_dir="~/.cache/huggingface/datasets/alpha_codium"